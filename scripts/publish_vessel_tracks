#!/bin/bash
source pipe-tools-utils

THIS_SCRIPT_DIR="$( cd "$(dirname "${BASH_SOURCE[0]}")" ; pwd -P )"
# source ${THIS_SCRIPT_DIR}/pipeline.sh
ASSETS=${THIS_SCRIPT_DIR}/../assets
ARGS=( \
  DATE_RANGE \
  SOURCE_ENCOUNTER_EVENTS \
  SOURCE_LOITERING_EVENTS \
  SOURCE_MESSAGES \
  SOURCE_SEGMENT_INFO \
  SOURCE_SEGMENT_VESSEL \
  TEMP_DATASET \
  TEMP_BUCKET \
  DEST_INSTANCE \
  DEST_DATABASE \
  DEST_TABLE \
  DEST_CONNECTION_STRING \
)

################################################################################
# Validate and extract arguments
################################################################################
display_usage() {
  ARG_NAMES=$(echo "${ARGS[*]}")
  echo -e "\nUsage:\n$0 $ARG_NAMES\n"
}

if [[ $# -ne ${#ARGS[@]} ]]
then
    display_usage
    exit 1
fi

echo "Running $0"
ARG_VALUES=("$@")
for index in ${!ARGS[*]}; do
  echo "  ${ARGS[$index]}=${ARG_VALUES[$index]}"
  declare "${ARGS[$index]}"="${ARG_VALUES[$index]}"
done

IFS=, read START_DATE END_DATE <<<"${DATE_RANGE}"
if [ -z $END_DATE ] || [ $END_DATE == $START_DATE ]; then
  END_DATE=$(date +%Y-%m-%d -d "$START_DATE + 1 day")
fi

################################################################################
# Generating track records into a temp table for exporting
################################################################################
echo "Generating track into temp table"
UUID=$(uuidgen)
TEMP_EXTRACT_TABLE="${TEMP_DATASET}.${UUID//-/_}"
EXTRACT_SQL=${ASSETS}/bigquery/tracks-aggregate-tracks.sql.j2
echo "  Running query to destionation table ${TEMP_EXTRACT_TABLE}"
jinja2 ${EXTRACT_SQL} \
  -D start=${START_DATE} \
  -D end=${END_DATE} \
  -D encounter_events=${SOURCE_ENCOUNTER_EVENTS//:/.} \
  -D loitering_events=${SOURCE_LOITERING_EVENTS//:/.} \
  -D messages=${SOURCE_MESSAGES//:/.} \
  -D segment_info=${SOURCE_SEGMENT_INFO//:/.} \
  -D segment_vessel=${SOURCE_SEGMENT_VESSEL//:/.} \
  | bq --headless query \
  -n 0 \
  --destination_table ${TEMP_EXTRACT_TABLE} \
  --use_legacy_sql=false
if [ "$?" -ne 0 ]; then
  echo "  Unable to fetch the records to export into ${TEMP_EXTRACT_TABLE}"
  exit 1
fi
echo "  Extracted the records to export into ${TEMP_EXTRACT_TABLE}"

################################################################################
# Export records to json files
################################################################################
echo "Exporting records from $TEMP_EXTRACT_TABLE"
TEMP_PATH=gs://${TEMP_BUCKET}/pipe-carrier-portal/publish-postgres-tracks/$( date -u "+%FT%T.%N" )
EXTRACT_PATH=$TEMP_PATH/bq/*.csv
bq --headless extract \
  --compression=GZIP \
  --print_header=false \
  --destination_format=CSV \
  $TEMP_EXTRACT_TABLE \
  $EXTRACT_PATH
if [ "$?" -ne 0 ]; then
  echo "  Unable to extract ${TEMP_EXTRACT_TABLE} to ${EXTRACT_PATH}"
  exit 1
fi
echo "  Exported records from ${TEMP_EXTRACT_TABLE} to ${EXTRACT_PATH}"

################################################################################
# Delete the temp extract table
################################################################################
echo "Deleting temp extract table ${TEMP_EXTRACT_TABLE}"
bq rm -t -f ${TEMP_EXTRACT_TABLE}
if [ "$?" -ne 0 ]; then
  echo "  Unable to delete the temp extract table ${TEMP_EXTRACT_TABLE}"
  exit 1
fi
echo "  Deleted the temp extract table ${TEMP_EXTRACT_TABLE}"

################################################################################
# Start the cloudsql proxy
################################################################################
echo "Starting the cloudsql proxy"
cloud_sql_proxy -instances=${DEST_INSTANCE}=tcp:5432 &
echo "  Waiting until database is ready at 127.0.0.1:5432"
sleep 5
i=0
while ! nc -v -w 5 127.0.0.1 5432 < /dev/null; do
  i=`expr $i + 1`
  if [ $i -ge 10 ]; then
    echo "    $(date) - still not reachable, giving up"
    exit 1
  fi
  echo "    $(date) - waiting $i/10"
  sleep 5
done
echo "  Database is ready"

################################################################################
# Load data into postgres
################################################################################
echo "Setting up database for data import"
SETUP_SQL=${ASSETS}/postgres/tracks/setup.sql.j2
jinja2 ${SETUP_SQL} \
  -D table_name=${DEST_TABLE} \
  -D start=${START_DATE} \
  -D end=${END_DATE} \
  | psql -v ON_ERROR_STOP=ON "${DEST_CONNECTION_STRING}"
if [ "$?" -ne 0 ]; then
  echo "  Unable to set database up for data import"
  exit 1
fi

echo "Importing data"
IFS=: read GCLOUD_SQL_PROJECT GCLOUD_SQL_REGION GCLOUD_SQL_INSTANCE <<<"${DEST_INSTANCE}"
echo "  Importing data to instance ${GCLOUD_SQL_INSTANCE} at project ${GCLOUD_SQL_PROJECT}"
CSV_FILES=$(gsutil ls ${EXTRACT_PATH})
for CSV_FILE in ${CSV_FILES}; do
  echo "  Importing data from file ${CSV_FILE}"
  JOB_URL=$( \
  gcloud sql import csv \
    ${GCLOUD_SQL_INSTANCE} \
    ${CSV_FILE} \
    --user=postgres \
    --quiet \
    --async \
    --project=${GCLOUD_SQL_PROJECT} \
    --database=${DEST_DATABASE} \
    --table=${DEST_TABLE} \
    --columns=seg_id,vessel_id,timestamp,position,score,speed,course \
  )
  if [ "$?" -ne 0 ]; then
    echo "  Unable to launch import process into postgres"
    exit 1
  fi

  echo "  Setting up poll process to read command status for command ${JOB_URL}"
  POLL_STATUS="\"RUNNING\""
  while [ "${POLL_STATUS}" == "\"RUNNING\"" ]; do
    echo "    Waiting 30s for import process ${JOB_URL} to complete, currently ${POLL_STATUS}"
    sleep 30
    POLL_STATUS=$(gcloud sql operations describe ${JOB_URL} --format json | jshon -e status)

    if [ "$?" -ne 0 ]; then
      echo "  Unable to check job status for job ${JOB_URL}"
      exit 1
    fi
  done

  echo "  After waiting for job status to complete, poll status is ${POLL_STATUS}"
  if [ ! "$POLL_STATUS" == "\"DONE\"" ]; then
    echo "  Job ${JOB_URL} failed with status code ${POLL_STATUS}"
    exit 1
  fi

  echo "  Import process copmleted successfully with poll status ${POLL_STATUS}"
done

echo "Indexing data"
INDEX_SQL=${ASSETS}/postgres/tracks/index.sql.j2
jinja2 ${INDEX_SQL} \
  -D table_name=${DEST_TABLE} \
  | psql -v ON_ERROR_STOP=ON "${DEST_CONNECTION_STRING}"
if [ "$?" -ne 0 ]; then
  echo "  Unable to set up indices for imported data"
  exit 1
fi
