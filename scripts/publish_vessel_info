#!/bin/bash
source pipe-tools-utils

THIS_SCRIPT_DIR="$( cd "$(dirname "${BASH_SOURCE[0]}")" ; pwd -P )"
ASSETS=${THIS_SCRIPT_DIR}/../assets
ARGS=( \
  SOURCE_ENCOUNTER_EVENTS \
  SOURCE_LOITERING_EVENTS \
  SOURCE_VESSEL_INFO \
  SOURCE_VESSEL_DATABASE \
  SOURCE_COUNTRY_CODES \
  SOURCE_RESEARCH_VESSEL_INFO \
  TEMP_DATASET \
  TEMP_BUCKET \
  ELASTIC_SEARCH_SERVER_URL \
  ELASTIC_SEARCH_INDEX_ALIAS \
)

################################################################################
# Validate and extract arguments
################################################################################
display_usage() {
  ARG_NAMES=$(echo "${ARGS[*]}")
  echo -e "\nUsage:\n$0 $ARG_NAMES\n"
}

if [[ $# -ne ${#ARGS[@]} ]]
then
    display_usage
    exit 1
fi

echo "Running $0"
ARG_VALUES=("$@")
for index in ${!ARGS[*]}; do
  echo "  ${ARGS[$index]}=${ARG_VALUES[$index]}"
  declare "${ARGS[$index]}"="${ARG_VALUES[$index]}"
done
################################################################################
# Running bigquery query to generate vessel information
################################################################################
echo "Running vessel information query"
UUID=$(uuidgen)
TEMP_EXTRACT_TABLE="${TEMP_DATASET}.${UUID//-/_}"
VESSEL_INFO_QUERY="${ASSETS}/bigquery/vessels-vessel-info.sql.j2"
echo "  Running query to destination table ${TEMP_EXTRACT_TABLE}"
jinja2 ${VESSEL_INFO_QUERY} \
  -D encounter_events=${SOURCE_ENCOUNTER_EVENTS//:/.} \
  -D loitering_events=${SOURCE_LOITERING_EVENTS//:/.} \
  -D vessel_info=${SOURCE_VESSEL_INFO//:/.} \
  -D vessel_database=${SOURCE_VESSEL_DATABASE//:/.} \
  -D country_codes=${SOURCE_COUNTRY_CODES//:/.} \
  -D vi_ssvid_by_year=${SOURCE_RESEARCH_VESSEL_INFO//:/.} \
  | bq query --max_rows=0 --allow_large_results --replace --destination_table ${TEMP_EXTRACT_TABLE}
if [ "$?" -ne 0 ]; then
  echo "  Unable to run vessel information query into ${TEMP_EXTRACT_TABLE}"
  exit 1
fi
echo "  Extracted vessel information into ${TEMP_EXTRACT_TABLE}"

#################################################################################
## Export records to json files
#################################################################################
echo "Exporting records from $TEMP_EXTRACT_TABLE"
TEMP_PATH=gs://${TEMP_BUCKET}/pipe-carrier-portal/publish-vessel-info/$( date -u "+%FT%T.%N" )
TEMP_EXTRACT_PATH=$TEMP_PATH/bq/*.json.gz
bq --headless extract \
  --compression=GZIP \
  --destination_format=NEWLINE_DELIMITED_JSON \
  $TEMP_EXTRACT_TABLE \
  $TEMP_EXTRACT_PATH
if [ "$?" -ne 0 ]; then
  echo "  Unable to extract ${TEMP_EXTRACT_TABLE} to ${TEMP_EXTRACT_PATH}"
  exit 1
fi
echo "  Exported records from ${TEMP_EXTRACT_TABLE} to ${TEMP_EXTRACT_PATH}"

################################################################################
# Delete the temp extract table
################################################################################
echo "Deleting temp extract table ${TEMP_EXTRACT_TABLE}"
bq rm -t -f ${TEMP_EXTRACT_TABLE}
if [ "$?" -ne 0 ]; then
  echo "  Unable to delete the temp extract table ${TEMP_EXTRACT_TABLE}"
  exit 1
fi
echo "  Deleted the temp extract table ${TEMP_EXTRACT_TABLE}"

################################################################################
# Download files locally
################################################################################
echo "Downloading records from ${TEMP_EXTRACT_PATH} to local disk"
LOCAL_JSON_PATH=./data/json/
mkdir -p ${LOCAL_JSON_PATH}
gsutil -m cp ${TEMP_EXTRACT_PATH} ${LOCAL_JSON_PATH}
if [ "$?" -ne 0 ]; then
  echo "  Unable to download records data locally from ${TEMP_EXTRACT_PATH}"
  exit 1
fi
echo "  Downloaded records from ${TEMP_EXTRACT_PATH}"

################################################################################
# Load data into Elastic Search
################################################################################
echo "Loading data into Elastic Search"
ELASTIC_SEARCH_INDEX_MAPPINGS=$(cat $ASSETS/elasticsearch/mappings.json)
zcat ${LOCAL_JSON_PATH}/*.json.gz \
  | python -u -m pipe_carrier_portal.elasticsearch.importer $ELASTIC_SEARCH_SERVER_URL $ELASTIC_SEARCH_SERVER_AUTH $ELASTIC_SEARCH_INDEX_ALIAS "$ELASTIC_SEARCH_INDEX_MAPPINGS"
if [ "$?" -ne 0 ]; then
  echo "  Unable to load data into Elastic Search"
  exit 1
fi
echo "  Loaded data into Elastic Search"
